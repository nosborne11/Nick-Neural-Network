{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nick_NN():\n",
    "    \n",
    "    \n",
    "###################################Initisilisng Parameters #################################################################################    \n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        ###### Default Parameters#######\n",
    "        self.Hidden_node_size=5\n",
    "        self.Output_node_size=1\n",
    "        self.Hidden_layers=2\n",
    "        self.iterations=10000\n",
    "        self.alpha=0.5\n",
    "        self.alpha_const=0.001    \n",
    "        self.momentum=0.9\n",
    "        \n",
    "        self.Z=-9999\n",
    "        \n",
    "        #######Overide Parameters#########\n",
    "        \n",
    "        self.args = ['Hidden_node_size', 'Output_node_size','Hidden_layers','iterations','alpha','alpha_const','momentum']\n",
    "        \n",
    "        for a in self.args:\n",
    "            if a in kwargs:\n",
    "                exec('self.'+a+' = kwargs[a]')\n",
    "                \n",
    "                \n",
    "        ################################################################\n",
    "\n",
    "        \n",
    "        #######Initiliasing further parameters#######\n",
    "        self.Input_layer_size=X.shape[1]       \n",
    "        self.weights=[]\n",
    "        self.constants=[] \n",
    "        \n",
    "        #######Initiliasing History ################\n",
    "        self.cost_history=np.zeros((self.iterations,self.Hidden_layers+1,1)) \n",
    "        self.Output_history=np.zeros((self.iterations,X.shape[0],1))\n",
    "        \n",
    "     \n",
    "\n",
    "     \n",
    "    \n",
    "###################################Functions of Neural Net #################################################################################    \n",
    "\n",
    "    ###############################Fitting the Neural Net ##########################################################    \n",
    "\n",
    "    def Fit_NN(self,X,Y):\n",
    "         \n",
    "                ###########Setting up neccessary lists and arrays to Fit NN###############\n",
    "        \n",
    "        Layers=[0]*(self.Hidden_layers+2)\n",
    "        Error=[0]*(self.Hidden_layers+1)\n",
    "        D_error=[0]*(self.Hidden_layers+1)\n",
    "        Slope=[0]*(self.Hidden_layers+1)\n",
    "        costs=np.zeros(self.Hidden_layers+1)\n",
    "        \n",
    "        \n",
    "                ##################Setting up weights and constants from input to 1st hidden layer############\n",
    "        weight=np.random.uniform(-2,2,size=(self.Input_layer_size,self.Hidden_node_size))\n",
    "        self.weights.append(weight) \n",
    "        \n",
    "        constant=np.zeros((1,self.Hidden_node_size))\n",
    "        self.constants.append(constant)\n",
    "                \n",
    "        change_constants=[]\n",
    "        change_constant=np.zeros((1,self.Hidden_node_size))\n",
    "        change_constants.append(change_constant) \n",
    "        \n",
    "        \n",
    "               \n",
    "        change_weights=[]\n",
    "        change_weight=np.zeros((self.Input_layer_size,self.Hidden_node_size))\n",
    "        change_weights.append(change_weight)          \n",
    "        \n",
    "            ##################Setting up weights and constants from 1st to nth hidden layer##############\n",
    "        if self.Hidden_layers>1:\n",
    "            for n in range(self.Hidden_layers-1):\n",
    "                n=n+1\n",
    "                weight=np.random.uniform(-2,2,size=(self.Hidden_node_size,self.Hidden_node_size))\n",
    "                self.weights.append(weight) \n",
    "                constant=np.zeros((1,self.Hidden_node_size))\n",
    "                self.constants.append(constant)\n",
    "                change_constant=np.zeros((1,self.Hidden_node_size))\n",
    "                change_constants.append(change_constant) \n",
    "                change_weight=np.zeros((self.Hidden_node_size,self.Hidden_node_size))\n",
    "                change_weights.append(change_weight) \n",
    "\n",
    "\n",
    "            ################Setting up weights and constants from nth to outer  layer##############\n",
    "    \n",
    "        weight=np.random.uniform(-2,2,size=(self.Hidden_node_size,self.Output_node_size))\n",
    "        self.weights.append(weight)\n",
    "        constant=np.zeros((1,self.Output_node_size))\n",
    "        self.constants.append(constant)\n",
    "        change_constant=np.zeros((1,self.Output_node_size))\n",
    "        change_constants.append(change_constant) \n",
    "        change_weight=np.zeros((self.Hidden_node_size,self.Output_node_size))\n",
    "        change_weights.append(change_weight) \n",
    "\n",
    "\n",
    "            ###############Start forward and Back Propogation for each iteration###########   \n",
    "        i=0\n",
    "        Layers[0]=X\n",
    "        Constant_history=[]\n",
    "        Weight_history=[]\n",
    "\n",
    "\n",
    "        while i<self.iterations:\n",
    "\n",
    "            Constant_history.append(self.constants.copy())\n",
    "            Weight_history.append(self.weights.copy())\n",
    "            \n",
    "            \n",
    "                #############Forward propagation####################   \n",
    "            for l in range(self.Hidden_layers+1):\n",
    "                FPN=Nick_NN.__For_Prop_Node(Layers[l],self.weights[l],self.constants[l])\n",
    "                Act=Nick_NN.__Act_func(FPN)\n",
    "                Layers[l+1]=Act     \n",
    "\n",
    "\n",
    "                ###############Backward propagation##################   \n",
    "            Error[self.Hidden_layers]=Layers[self.Hidden_layers+1]-Y\n",
    "            Slope[self.Hidden_layers]=Nick_NN.__Der_Act_func(Layers[self.Hidden_layers+1])\n",
    "            D_error[self.Hidden_layers]=Error[self.Hidden_layers]*Slope[self.Hidden_layers]\n",
    "            costs[self.Hidden_layers]=Nick_NN.__cost_function(Layers[self.Hidden_layers],Y,self.weights[self.Hidden_layers],self.constants[self.Hidden_layers])\n",
    "            for l in range(self.Hidden_layers):\n",
    "                z=(self.Hidden_layers-1)-l        \n",
    "                Error[z]=D_error[z+1].dot(self.weights[z+1].T) \n",
    "                Slope[z]=Nick_NN.__Der_Act_func(Layers[z+1])\n",
    "                D_error[z]=Error[z]*Slope[z]\n",
    "                Layer_adj=Layers[z+1]+Error[z]\n",
    "                costs[z]=Nick_NN.__cost_function(Layers[z],Layer_adj,self.weights[z],self.constants[z])\n",
    "            for l in range(self.Hidden_layers+1):\n",
    "                z=self.Hidden_layers-l\n",
    "                self.weights[z],change_weights[z]=Nick_NN.__Back_Prop_Node(D_error[z],Y,Layers[z],self.weights[z],self.alpha,self.momentum,change_weights[z])  \n",
    "                change_constants[z]=np.sum(D_error[z],axis=0)*self.alpha_const+change_constants[z]*self.momentum\n",
    "                self.constants[z]=self.constants[z]-change_constants[z]\n",
    "                \n",
    "            \n",
    "            self.Output_history[i]=Layers[self.Hidden_layers+1]\n",
    "\n",
    "            for l in range(self.Hidden_layers+1):   \n",
    "                self.cost_history[i][l]=costs[l]   \n",
    "            i=i+1\n",
    "            \n",
    "        return self.Output_history[-1:][0]\n",
    "    \n",
    "    \n",
    "     ###############################Prediction ########################################################## \n",
    "    \n",
    "    def Score(self,Xt):\n",
    "        Layers_test=[0]*(self.Hidden_layers+2)\n",
    "        Layers_test[0]=Xt\n",
    "        for l in range(self.Hidden_layers+1):\n",
    "            FPN=Nick_NN.__For_Prop_Node(Layers_test[l],self.weights[l],self.constants[l])\n",
    "            Act=Nick_NN.__Act_func(FPN)\n",
    "            Layers_test[l+1]=Act \n",
    "    \n",
    "        Output_test=Layers_test[self.Hidden_layers+1]    \n",
    "        return Output_test\n",
    "    \n",
    "    \n",
    "    ############################### ROC Curve ########################################################## \n",
    "\n",
    "    def ROC(self,Actual,Output,Title):\n",
    "        join=np.column_stack([Output,Actual])\n",
    "        join=join[join[:,0].argsort()][::-1]\n",
    "        Y_ax=0\n",
    "        X_ax=0\n",
    "        ROC_Data=np.array([[0,0]])\n",
    "        for x in join:\n",
    "            if x[1]==1:\n",
    "                Y_ax=Y_ax+1\n",
    "            if x[1]==0:\n",
    "                X_ax=X_ax+1\n",
    "            new_roc=np.array([[Y_ax,X_ax]])\n",
    "            ROC_Data=np.concatenate((ROC_Data,new_roc),axis=0)  \n",
    "        ROC_Data=ROC_Data/[ROC_Data[-1][0],ROC_Data[-1][1]]\n",
    "        Z=[0,1]\n",
    "        plt.clf()\n",
    "        plt.plot(ROC_Data[:,1],ROC_Data[:,0])\n",
    "        plt.plot(Z)\n",
    "        plt.title(Title)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positve Rate')\n",
    "        plt.show() \n",
    "\n",
    "###############################################Get Functions ###################################################################    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def Get_Parameters(self):  \n",
    "        for a in self.args:\n",
    "            exec('self.Z; self.Z=self.'+a)\n",
    "            print(a+': '+str(self.Z))\n",
    "        \n",
    "\n",
    "    def Get_Weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def Get_Constants(self):\n",
    "        return self.constants\n",
    "    \n",
    "    def Get_Cost_History(self):\n",
    "        return self.cost_history\n",
    "    \n",
    "    def Get_Output_History(self):\n",
    "        return self.Output_history\n",
    "       \n",
    "    \n",
    "###############################################Inner Functions ###################################################################    \n",
    "\n",
    "\n",
    "\n",
    "    ######forward Propogation##############\n",
    "\n",
    "    def __For_Prop_Node(X,weights,constant):\n",
    "        output=np.dot(X,weights)+constant\n",
    "        return output\n",
    "\n",
    "    ######Backward Propogation##############\n",
    "\n",
    "    def __Back_Prop_Node(Error,Y,X,theta,alpha,m,change_theta):\n",
    "        gradiant=X.T.dot(Error)/len(Y)\n",
    "        change_theta=gradiant*alpha+ m*change_theta\n",
    "        theta= theta-change_theta\n",
    "        return theta,change_theta\n",
    "\n",
    "\n",
    "    ######Cost Function##############\n",
    "\n",
    "    def __cost_function(X, Y, theta, constant):\n",
    "        Expected=X.dot(theta)+constant\n",
    "        Expected=Nick_NN.__Act_func(Expected)\n",
    "        J = np.sum((Expected-Y)**2)/2/len(Y)    \n",
    "        return J\n",
    "\n",
    "    ######Activation Function##############\n",
    "\n",
    "\n",
    "    def __Act_func(x):\n",
    "        #return x \n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    ######Derivative of Activation Function##############\n",
    "    \n",
    "    def __Der_Act_func(x):\n",
    "        return Nick_NN.__Act_func(x)*(1-Nick_NN.__Act_func(x))\n",
    "\n",
    "    \n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
